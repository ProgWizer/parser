import asyncio
import os
import shutil
import re
import pandas as pd
from io import StringIO
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
from contextlib import asynccontextmanager
import logging
import uuid
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á
current_tasks: Dict[str, Dict] = {}
task_results: Dict[str, Dict] = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # Startup
    logger.info("–ó–∞–ø—É—Å–∫ File Processor API...")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    data_dir = "/app/data"
    tests_dir = os.path.join(data_dir, "Tests")
    results_dir = os.path.join(data_dir, "Results")

    os.makedirs(tests_dir, exist_ok=True)
    os.makedirs(results_dir, exist_ok=True)

    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö: {data_dir}")
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ç–µ—Å—Ç–æ–≤: {tests_dir}")
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {results_dir}")

    yield

    # Shutdown
    logger.info("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")


app = FastAPI(title="File Processor API", lifespan=lifespan)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class PathRequest(BaseModel):
    path: str


class TaskResponse(BaseModel):
    task_id: str
    message: str
    timestamp: str


class LogMessage(BaseModel):
    message: str
    type: str = "info"


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def add_log_to_task(task_id: str, message: str, type: str = "info"):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–æ–≥ –≤ –∑–∞–¥–∞—á—É"""
    if task_id not in current_tasks:
        current_tasks[task_id] = {"logs": [], "status": "running"}

    # –î–æ–±–∞–≤–ª—è–µ–º timestamp –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
    timestamp = datetime.now().strftime("%H:%M:%S")
    formatted_message = f"[{timestamp}] {message}"

    current_tasks[task_id]["logs"].append(LogMessage(message=formatted_message, type=type))

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000)
    if len(current_tasks[task_id]["logs"]) > 1000:
        current_tasks[task_id]["logs"] = current_tasks[task_id]["logs"][-1000:]


# ========== –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –§–ê–ô–õ–û–í ==========

def find_all_broken_files(root_path: str, task_id: str):
    """–ù–∞—Ö–æ–¥–∏—Ç –í–°–ï –±–∏—Ç—ã–µ .tst —Ñ–∞–π–ª—ã –±–µ–∑ –ø–∞—Ä–Ω—ã—Ö .txt –≤–æ –í–°–ï–• –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–∞–ø–∫–∞—Ö"""
    add_log_to_task(task_id, "üîç –ù–ê–ß–ò–ù–ê–ï–ú –†–ï–ö–£–†–°–ò–í–ù–´–ô –ü–û–ò–°–ö –í–û –í–°–ï–• –ü–ê–ü–ö–ê–•...", "info")
    add_log_to_task(task_id, "============================================", "info")

    total_found = 0
    total_processed = 0
    moved_files = []

    def walk(directory):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –≤—Å–µ—Ö –ø–∞–ø–æ–∫"""
        for root, dirs, files in os.walk(directory):
            yield root, dirs, files

    for folder, dirs, files in walk(root_path):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫—É "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ" –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ" in folder:
            continue
            
        add_log_to_task(task_id, f"üìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–∫–∏: {os.path.basename(folder)}", "info")

        tst_files = sorted([f for f in files if f.lower().endswith(".tst")])
        
        if not tst_files:
            add_log_to_task(task_id, "   ‚Üí .tst —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", "info")
            continue
            
        add_log_to_task(task_id, f"   ‚Üí .tst –Ω–∞–π–¥–µ–Ω–æ: {len(tst_files)}", "info")

        folder_found = 0
        for tst in tst_files:
            total_processed += 1
            base = os.path.splitext(tst)[0]
            txt = base + ".txt"
            txt_path = os.path.join(folder, txt)

            if not os.path.exists(txt_path):
                # –ù–∞–π–¥–µ–Ω –±–∏—Ç—ã–π —Ñ–∞–π–ª
                src = os.path.join(folder, tst)
                dest_dir = os.path.join(root_path, "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ")
                os.makedirs(dest_dir, exist_ok=True)
                
                # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫—É —Å –∏–º–µ–Ω–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏
                relative_path = os.path.relpath(folder, root_path)
                if relative_path != ".":
                    dest_dir = os.path.join(dest_dir, relative_path)
                    os.makedirs(dest_dir, exist_ok=True)
                
                dst = os.path.join(dest_dir, tst)

                try:
                    shutil.move(src, dst)
                    total_found += 1
                    folder_found += 1
                    moved_files.append({
                        "file": tst,
                        "from": folder,
                        "to": dest_dir,
                        "reason": f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {txt}"
                    })

                    add_log_to_task(task_id, "--- ‚ùå –ë–ò–¢–´–ô –§–ê–ô–õ –ù–ê–ô–î–ï–ù ---", "warning")
                    add_log_to_task(task_id, f"   –§–∞–π–ª: {tst}", "success")
                    add_log_to_task(task_id, f"   –ü–∞–ø–∫–∞: {os.path.basename(folder)}", "info")
                    add_log_to_task(task_id, f"   –ü—Ä–∏—á–∏–Ω–∞: –Ω–µ—Ç {txt}", "info")
                    add_log_to_task(task_id, f"   –ü–µ—Ä–µ–º–µ—â—ë–Ω –≤: {dest_dir}", "info")
                    add_log_to_task(task_id, "---------------------------", "info")

                except Exception as e:
                    add_log_to_task(task_id, f"   ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è: {e}", "error")
                    
        if folder_found > 0:
            add_log_to_task(task_id, f"   ‚úÖ –í –ø–∞–ø–∫–µ –Ω–∞–π–¥–µ–Ω–æ –±–∏—Ç—ã—Ö: {folder_found}", "success")

    if total_found > 0:
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üéâ –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù! –ù–ê–ô–î–ï–ù–û: {total_found} –ë–ò–¢–´–• –§–ê–ô–õ–û–í", "success")
        add_log_to_task(task_id, f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_processed}", "info")
        add_log_to_task(task_id, f"üìÅ –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ –≤: {os.path.join(root_path, '–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ')}", "info")
        add_log_to_task(task_id, "=" * 50, "info")
        
        return {
            "found": total_found,
            "processed": total_processed,
            "moved_files": moved_files,
            "target_folder": os.path.join(root_path, "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ"),
            "message": f"–ù–∞–π–¥–µ–Ω–æ {total_found} –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤"
        }
    else:
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, "‚úÖ –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!", "success")
        add_log_to_task(task_id, f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_processed}", "info")
        add_log_to_task(task_id, "üì≠ –ë–ò–¢–´–• –§–ê–ô–õ–û–í –ù–ï –ù–ê–ô–î–ï–ù–û", "success")
        add_log_to_task(task_id, "=" * 50, "info")
        
        return {
            "found": 0,
            "processed": total_processed,
            "message": "–ë–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
        }


def parse_files_task(input_folder: str, task_id: str):
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    add_log_to_task(task_id, f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤: {input_folder}", "info")

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É Results —Ä—è–¥–æ–º —Å Tests
    data_dir = "/app/data"
    relative_path = os.path.relpath(input_folder, data_dir)
    output_folder = os.path.join(data_dir, "Results", relative_path)
    os.makedirs(output_folder, exist_ok=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    report_summary = {
        "–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ": 0,
        "UCA —Ñ–∞–π–ª—ã": 0,
        "–£–ª—å—Ç—Ä–∞–ó–≤—É–∫ —Ñ–∞–π–ª—ã": 0,
        "UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏": 0,
        "–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è": 0,
        "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA": {}
    }

    # –§—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    def parse_summary_line(line):
        parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
        if not parts:
            return None, None
        if len(parts) == 3 and parts[0] in ("Information", "Calculated Curve"):
            return parts[1], parts[2]
        if len(parts) >= 2:
            return parts[0], " ".join(parts[1:])
        return parts[0], ""

    def get_density_range(density_value):
        try:
            density_str = re.findall(r"(\d+)", str(density_value))[0]
            density = int(density_str)
        except Exception:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è_–ø–ª–æ—Ç–Ω–æ—Å—Ç—å"

        if 1100 <= density <= 1499:
            return "1100-1499"
        elif 1500 <= density <= 1899:
            return "1500-1899"
        elif 1900 <= density <= 2500:
            return "1900-2500"
        else:
            return f"–î—Ä—É–≥–∞—è_{density}"

    def get_strength_type(value):
        val = str(value).lower()

        if "more than 14" in val:
            return "–ê–ª–≥–æ—Ä–∏—Ç–º_–±–æ–ª—å—à–µ_14"
        elif "less than 14" in val:
            return "–ê–ª–≥–æ—Ä–∏—Ç–º_–º–µ–Ω—å—à–µ_14"
        elif val.strip():
            cleaned_val = (
                val.strip()
                .replace('/', '_')
                .replace(':', '')
                .replace('<', '–º–µ–Ω—å—à–µ_')
                .replace('>', '–±–æ–ª—å—à–µ_')
                .replace('*', 'star')
                .replace('?', '')
            )
            return f"–ê–ª–≥–æ—Ä–∏—Ç–º_{cleaned_val}"
        else:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π_–∞–ª–≥–æ—Ä–∏—Ç–º"

    def get_cement_class(value):
        if not value or pd.isna(value):
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π_—Ü–µ–º–µ–Ω—Ç"
        val = str(value).strip().replace("/", "_").replace(':', '').replace('<', '–º–µ–Ω—å—à–µ').replace('>', '–±–æ–ª—å—à–µ').replace('*', 'star').replace('?', '')
        return f"–¶–µ–º–µ–Ω—Ç_{val}"

    def get_value(df, key_fragment):
        res = df[df["–ü–∞—Ä–∞–º–µ—Ç—Ä"].str.contains(key_fragment, case=False, na=False)]["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        return res.iloc[0] if not res.empty else None

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        txt_files = []
        for root, dirs, files in os.walk(input_folder):
            for file in files:
                if file.lower().endswith('.txt'):
                    txt_files.append((root, file))
                    
        add_log_to_task(task_id, f"üìÑ –ù–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(txt_files)}", "info")

        for root, file_name in txt_files:
            report_summary["–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"] += 1
            input_path = os.path.join(root, file_name)
            relative_root = os.path.relpath(root, input_folder)

            add_log_to_task(task_id, f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_name}", "info")
            if relative_root != ".":
                add_log_to_task(task_id, f"   üìÅ –ü–∞–ø–∫–∞: {relative_root}", "info")

            try:
                with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
            except Exception as e:
                add_log_to_task(task_id, f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_name}: {e}", "error")
                report_summary["–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è"] += 1
                continue

            # –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü –±–ª–æ–∫–æ–≤
            summary_start, data_start = None, None
            for i, line in enumerate(lines):
                if "--Summary--" in line or "--Test Summary--" in line:
                    summary_start = i
                elif "--Data--" in line:
                    data_start = i
                    break

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            is_uca_file = False
            summary_df = None

            if summary_start is not None and data_start is not None:
                summary_lines = lines[summary_start + 1:data_start]
                summary_data = []
                for line in summary_lines:
                    if not line.strip() or line.startswith("Full Path and File Name"):
                        continue
                    key, value = parse_summary_line(line)
                    if key:
                        summary_data.append((key, value))

                summary_df = pd.DataFrame(summary_data, columns=["–ü–∞—Ä–∞–º–µ—Ç—Ä", "–ó–Ω–∞—á–µ–Ω–∏–µ"])

                instrument_type = get_value(summary_df, "Instrument Type")

                if instrument_type and "uca" in str(instrument_type).lower():
                    is_uca_file = True
                    add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ Instrument Type)", "success")

            # 2. –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if not is_uca_file and "uca" in file_name.lower():
                is_uca_file = True
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê UCA ---
            if is_uca_file:
                report_summary["UCA —Ñ–∞–π–ª—ã"] += 1

                if summary_df is None:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫: UCA-—Ñ–∞–π–ª –±–µ–∑ –±–ª–æ–∫–æ–≤ Summary/Data", "warning")
                    report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                    continue

                density_val = get_value(summary_df, "Density")
                strength_val = get_value(summary_df, "Compressive Strength")
                cement_val = get_value(summary_df, "CementClass")

                missing_params = []
                if not density_val:
                    missing_params.append("Density")
                if not strength_val:
                    missing_params.append("Compressive Strength")
                if not cement_val:
                    missing_params.append("CementClass")

                if not missing_params:
                    density_folder = get_density_range(density_val)
                    algorithm_folder = get_strength_type(strength_val)
                    cement_folder = get_cement_class(cement_val)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
                    if relative_root != ".":
                        target_folder = os.path.join(output_folder, relative_root, density_folder, algorithm_folder, cement_folder)
                    else:
                        target_folder = os.path.join(output_folder, density_folder, algorithm_folder, cement_folder)
                        
                    category_key = f"{density_folder}/{algorithm_folder}/{cement_folder}"
                    add_log_to_task(task_id,
                                    f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: –ü–ª–æ—Ç–Ω–æ—Å—Ç—å={density_folder}, –ü—Ä–æ—á–Ω–æ—Å—Ç—å={algorithm_folder}, –¶–µ–º–µ–Ω—Ç={cement_folder}",
                                    "success")
                else:
                    target_folder = os.path.join(output_folder, relative_root, "–ù–µ–ø–æ–ª–Ω—ã–µ")
                    category_key = "–ù–µ–ø–æ–ª–Ω—ã–µ"
                    report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –ù–µ–ø–æ–ª–Ω—ã–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç {', '.join(missing_params)}",
                                    "warning")

                if category_key not in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
                    report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] = 0
                report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] += 1

                os.makedirs(target_folder, exist_ok=True)

                # Data —á–∞—Å—Ç—å
                data_lines = lines[data_start + 1:] if data_start else []
                data_str = "".join(data_lines).replace(",", ".")

                try:
                    data_df = pd.read_csv(StringIO(data_str), sep="\t")
                except Exception as e:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Data –≤ {file_name}: {e}", "error")
                    if category_key != '–ù–µ–ø–æ–ª–Ω—ã–µ':
                        report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                        if category_key in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
                            report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] -= 1
                        report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]["–ù–µ–ø–æ–ª–Ω—ã–µ"] = report_summary[
                                                                                           "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"].get(
                            "–ù–µ–ø–æ–ª–Ω—ã–µ", 0) + 1

                    target_folder = os.path.join(output_folder, relative_root, "–ù–µ–ø–æ–ª–Ω—ã–µ")
                    os.makedirs(target_folder, exist_ok=True)
                    data_df = None
                    category_key = "–ù–µ–ø–æ–ª–Ω—ã–µ"

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                base_name = os.path.splitext(file_name)[0]
                summary_path = os.path.join(target_folder, f"{base_name}_summary.xlsx")
                summary_df.to_excel(summary_path, index=False)

                if data_df is not None:
                    data_path = os.path.join(target_folder, f"{base_name}_data.xlsx")
                    data_df.to_excel(data_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {target_folder}", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï-UCA (–£–ª—å—Ç—Ä–∞–ó–≤—É–∫) ---
            else:
                report_summary["–£–ª—å—Ç—Ä–∞–ó–≤—É–∫ —Ñ–∞–π–ª—ã"] += 1
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: –£–ª—å—Ç—Ä–∞–ó–≤—É–∫", "info")

                rows = []
                for line in lines:
                    parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
                    if parts:
                        rows.append(parts)

                if not rows:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –§–∞–π–ª {file_name} –ø—É—Å—Ç", "warning")
                    report_summary["–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è"] += 1
                    continue

                max_cols = max(len(r) for r in rows)
                col_names = [f"–ö–æ–ª–æ–Ω–∫–∞_{i + 1}" for i in range(max_cols)]
                df = pd.DataFrame([r + [''] * (max_cols - len(r)) for r in rows], columns=col_names)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
                if relative_root != ".":
                    ultrasound_folder = os.path.join(output_folder, relative_root, "–£–ª—å—Ç—Ä–∞–ó–≤—É–∫")
                else:
                    ultrasound_folder = os.path.join(output_folder, "–£–ª—å—Ç—Ä–∞–ó–≤—É–∫")
                    
                os.makedirs(ultrasound_folder, exist_ok=True)

                base_name = os.path.splitext(file_name)[0]
                excel_path = os.path.join(ultrasound_folder, f"{base_name}.xlsx")
                df.to_excel(excel_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {ultrasound_folder}", "success")

        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, "üéâ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢", "success")
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üìÅ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {report_summary['–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ']}", "info")
        add_log_to_task(task_id, f"üîπ UCA-—Ñ–∞–π–ª—ã: {report_summary['UCA —Ñ–∞–π–ª—ã']}", "info")
        add_log_to_task(task_id, f"üîπ –£–ª—å—Ç—Ä–∞–ó–≤—É–∫: {report_summary['–£–ª—å—Ç—Ä–∞–ó–≤—É–∫ —Ñ–∞–π–ª—ã']}", "info")
        add_log_to_task(task_id, f"üîπ –ù–µ–ø–æ–ª–Ω—ã–µ/–û—à–∏–±–∫–∏: {report_summary['UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏']}", "info")
        add_log_to_task(task_id, f"üîπ –û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è: {report_summary['–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è']}", "info")

        add_log_to_task(task_id, "\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï UCA-–§–ê–ô–õ–û–í:", "info")
        if report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
            for category, count in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"].items():
                add_log_to_task(task_id, f"  - {category}: {count} —à—Ç.", "info")
        else:
            add_log_to_task(task_id, "  (–ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö UCA-—Ñ–∞–π–ª–æ–≤)", "info")

        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_folder}", "success")
        add_log_to_task(task_id, "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")

        return {
            "processed": report_summary["–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"],
            "output_folder": output_folder,
            "summary": report_summary
        }

    except Exception as e:
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}", "error")
        return {"error": str(e), "processed": 0}


# ========== API –≠–ù–î–ü–û–ò–ù–¢–´ ==========

@app.get("/")
async def root():
    return {
        "message": "File Processor API",
        "—Å—Ç–∞—Ç—É—Å": "—Ä–∞–±–æ—Ç–∞–µ—Ç",
        "—Ä—É—Å—Å–∫–∞—è_–≤–µ—Ä—Å–∏—è": "API –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤",
        "endpoints": [
            "/api/find-broken-files (POST) - –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤",
            "/api/parse-files (POST) - –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤",
            "/api/folders (GET) - —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –≤ data",
            "/api/task/{task_id}/logs (GET) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤",
            "/api/task/{task_id}/status (GET) - —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏",
            "/docs - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API"
        ]
    }


def get_folder_structure(base_path: str):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫"""
    structure = []
    
    try:
        for item in os.listdir(base_path):
            item_path = os.path.join(base_path, item)
            if os.path.isdir(item_path):
                # –°—á–∏—Ç–∞–µ–º .txt —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ –∏ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
                txt_count = 0
                for root, dirs, files in os.walk(item_path):
                    txt_count += len([f for f in files if f.lower().endswith('.txt')])
                
                folder_info = {
                    "name": item,
                    "path": item_path,
                    "files_count": txt_count,
                    "has_txt_files": txt_count > 0
                }
                
                # –ü–æ–ª—É—á–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
                subfolders = []
                try:
                    for sub_item in os.listdir(item_path):
                        sub_item_path = os.path.join(item_path, sub_item)
                        if os.path.isdir(sub_item_path):
                            sub_txt_count = 0
                            for root, dirs, files in os.walk(sub_item_path):
                                sub_txt_count += len([f for f in files if f.lower().endswith('.txt')])
                            
                            if sub_txt_count > 0:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏
                                subfolders.append({
                                    "name": sub_item,
                                    "path": sub_item_path,
                                    "files_count": sub_txt_count,
                                    "has_txt_files": sub_txt_count > 0
                                })
                except PermissionError:
                    pass
                
                if subfolders:
                    folder_info["subfolders"] = sorted(subfolders, key=lambda x: x["name"])
                
                structure.append(folder_info)
                
    except PermissionError as e:
        logger.error(f"Permission error accessing {base_path}: {e}")
    except Exception as e:
        logger.error(f"Error scanning {base_path}: {e}")
    
    return sorted(structure, key=lambda x: x["name"])


@app.get("/api/folders")
async def get_folders():
    """–ü–æ–ª—É—á–∞–µ—Ç –¥—Ä–µ–≤–æ–≤–∏–¥–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    data_dir = "/app/data"

    if not os.path.exists(data_dir):
        os.makedirs(data_dir, exist_ok=True)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    folders = get_folder_structure(data_dir)
    
    return {
        "data_directory": data_dir,
        "folders": folders
    }


@app.post("/api/find-broken-files", response_model=TaskResponse)
async def find_broken_files(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ - –î–õ–Ø –ì–õ–ê–í–ù–û–ô –°–¢–†–ê–ù–ò–¶–´"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "find-broken",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat()
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_find_broken_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ find-broken-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


@app.post("/api/parse-files", response_model=TaskResponse)
async def parse_files_endpoint(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ - –î–õ–Ø –°–¢–†–ê–ù–ò–¶–´ –ü–ê–†–°–ï–†–ê"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "parse",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat()
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_parse_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ parse-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


# ========== –§–û–ù–û–í–´–ï –ó–ê–î–ê–ß–ò ==========

async def process_find_broken_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–æ–∏—Å–∫–∞ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - –î–õ–Ø –ì–õ–ê–í–ù–û–ô –°–¢–†–ê–ù–ò–¶–´"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            find_all_broken_files,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
            input_path,
            task_id
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        task_results[task_id] = result

        # –û—Ç–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result

        add_log_to_task(task_id, "‚úÖ –ó–∞–¥–∞—á–∞ –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ process_find_broken_task: {e}")
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)


async def process_parse_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –î–õ–Ø –°–¢–†–ê–ù–ò–¶–´ –ü–ê–†–°–ï–†–ê"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤...", "info")

        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            parse_files_task,
            input_path,
            task_id
        )

        task_results[task_id] = result
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result

        add_log_to_task(task_id, "‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!", "success")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ process_parse_task: {e}")
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)


# ========== –≠–ù–î–ü–û–ò–ù–¢–´ –î–õ–Ø –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–Ø ==========

@app.get("/api/task/{task_id}/logs")
async def get_task_logs(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    task_info = current_tasks[task_id].copy()
    logs = task_info.get("logs", [])

    return {
        "task_id": task_id,
        "status": task_info.get("status", "unknown"),
        "type": task_info.get("type"),
        "folder_name": task_info.get("folder_name"),
        "started_at": task_info.get("started_at"),
        "completed_at": task_info.get("completed_at"),
        "logs": [log.dict() for log in logs]
    }


@app.get("/api/task/{task_id}/status")
async def get_task_status(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return {
        "task_id": task_id,
        "status": current_tasks[task_id].get("status", "unknown"),
        "type": current_tasks[task_id].get("type"),
        "started_at": current_tasks[task_id].get("started_at"),
        "completed_at": current_tasks[task_id].get("completed_at"),
        "has_result": task_id in task_results
    }


@app.get("/api/task/{task_id}/result")
async def get_task_result(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in task_results:
        raise HTTPException(status_code=404, detail="–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

    return {
        "task_id": task_id,
        "result": task_results[task_id],
        "retrieved_at": datetime.now().isoformat()
    }


@app.get("/api/tasks")
async def get_all_tasks():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    tasks = []
    for task_id, task_info in current_tasks.items():
        tasks.append({
            "id": task_id,
            "status": task_info.get("status", "unknown"),
            "type": task_info.get("type"),
            "folder_name": task_info.get("folder_name"),
            "started_at": task_info.get("started_at"),
            "logs_count": len(task_info.get("logs", []))
        })

    return {"tasks": tasks}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)