import asyncio
import os
import shutil
import re
import pandas as pd
from io import StringIO
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
from contextlib import asynccontextmanager
import logging
import uuid
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á
current_tasks: Dict[str, Dict] = {}
task_results: Dict[str, Dict] = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # Startup
    logger.info("Starting File Processor API...")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    data_dir = "/app/data"
    tests_dir = os.path.join(data_dir, "Tests")
    results_dir = os.path.join(data_dir, "Results")

    os.makedirs(tests_dir, exist_ok=True)
    os.makedirs(results_dir, exist_ok=True)

    logger.info(f"Data directory: {data_dir}")
    logger.info(f"Tests directory: {tests_dir}")
    logger.info(f"Results directory: {results_dir}")

    yield

    # Shutdown
    logger.info("Shutting down...")


app = FastAPI(title="File Processor API", lifespan=lifespan)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class PathRequest(BaseModel):
    path: str


class TaskResponse(BaseModel):
    task_id: str
    message: str
    timestamp: str


class LogMessage(BaseModel):
    message: str
    type: str = "info"


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def add_log_to_task(task_id: str, message: str, type: str = "info"):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–æ–≥ –≤ –∑–∞–¥–∞—á—É"""
    if task_id not in current_tasks:
        current_tasks[task_id] = {"logs": [], "status": "running"}

    # –î–æ–±–∞–≤–ª—è–µ–º timestamp –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
    timestamp = datetime.now().strftime("%H:%M:%S")
    formatted_message = f"[{timestamp}] {message}"

    current_tasks[task_id]["logs"].append(LogMessage(message=formatted_message, type=type))

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000)
    if len(current_tasks[task_id]["logs"]) > 1000:
        current_tasks[task_id]["logs"] = current_tasks[task_id]["logs"][-1000:]


# ========== –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –§–ê–ô–õ–û–í ==========

def isolate_one_broken_tst(root_path: str, task_id: str):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ—Ç .tst —Ñ–∞–π–ª—ã –±–µ–∑ –ø–∞—Ä–Ω–æ–≥–æ .txt"""
    add_log_to_task(task_id, "üîç –ù–ê–ß–ò–ù–ê–ï–ú –†–ï–ö–£–†–°–ò–í–ù–´–ô –ü–û–ò–°–ö...", "info")
    add_log_to_task(task_id, "==============================", "info")

    found_count = 0
    processed_count = 0

    def walk(directory):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –ø–∞–ø–æ–∫"""
        yield directory
        for entry in os.scandir(directory):
            if entry.is_dir() and entry.name != "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ":
                yield from walk(entry.path)

    for folder in walk(root_path):
        add_log_to_task(task_id, f"üìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–∫–∏: {folder}", "info")

        try:
            items = os.listdir(folder)
        except Exception as e:
            add_log_to_task(task_id, f"   ‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞: {e}", "error")
            continue

        tst_files = sorted([f for f in items if f.lower().endswith(".tst")])
        add_log_to_task(task_id, f"   ‚Üí .tst –Ω–∞–π–¥–µ–Ω–æ: {len(tst_files)}", "info")

        for tst in tst_files:
            base = os.path.splitext(tst)[0]
            txt = base + ".txt"
            txt_path = os.path.join(folder, txt)

            if not os.path.exists(txt_path):
                # –ù–ê–°–¢–û–Ø–©–ò–ô –±–∏—Ç—ã–π —Ñ–∞–π–ª ‚Äî –ø–µ—Ä–µ–º–µ—â–∞–µ–º –µ–≥–æ
                src = os.path.join(folder, tst)
                dest_dir = os.path.join(folder, "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ")
                os.makedirs(dest_dir, exist_ok=True)
                dst = os.path.join(dest_dir, tst)

                try:
                    shutil.move(src, dst)
                    found_count += 1

                    add_log_to_task(task_id, "--- ‚ùå –§–ê–ô–õ –ò–ó–û–õ–ò–†–û–í–ê–ù ---", "warning")
                    add_log_to_task(task_id, f"   –§–∞–π–ª: {tst}", "success")
                    add_log_to_task(task_id, f"   –ü—Ä–∏—á–∏–Ω–∞: –Ω–µ—Ç {txt}", "info")
                    add_log_to_task(task_id, f"   –ü–µ—Ä–µ–º–µ—â—ë–Ω –≤: {dest_dir}", "info")
                    add_log_to_task(task_id, "---------------------------", "info")

                    return {
                        "found": 1,
                        "processed": processed_count + 1,
                        "moved_to": dst,
                        "reason": f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {txt}"
                    }

                except Exception as e:
                    add_log_to_task(task_id, f"   ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è: {e}", "error")

            processed_count += 1

    add_log_to_task(task_id, "‚úÖ –°–±–æ–µ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö.", "success")
    return {
        "found": 0,
        "processed": processed_count,
        "message": "–ë–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
    }


def parse_files_task(input_folder: str, task_id: str):
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    add_log_to_task(task_id, f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤: {input_folder}", "info")

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É Results —Ä—è–¥–æ–º —Å Tests
    output_folder = os.path.join(os.path.dirname(input_folder), "Results", os.path.basename(input_folder))
    os.makedirs(output_folder, exist_ok=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    report_summary = {
        "Total Files Processed": 0,
        "UCA Files": 0,
        "Non-UCA Files (–£–ª—å—Ç—Ä–∞–ó–≤—É–∫)": 0,
        "UCA - Incomplete/Error": 0,
        "Errors (Read/Other)": 0,
        "Distribution by UCA Category": {}
    }

    # –§—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
    def parse_summary_line(line):
        parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
        if not parts:
            return None, None
        if len(parts) == 3 and parts[0] in ("Information", "Calculated Curve"):
            return parts[1], parts[2]
        if len(parts) >= 2:
            return parts[0], " ".join(parts[1:])
        return parts[0], ""

    def get_density_range(density_value):
        try:
            density_str = re.findall(r"(\d+)", str(density_value))[0]
            density = int(density_str)
        except Exception:
            return "Unknown_Density"

        if 1100 <= density <= 1499:
            return "1100-1499"
        elif 1500 <= density <= 1899:
            return "1500-1899"
        elif 1900 <= density <= 2500:
            return "1900-2500"
        else:
            return f"Other_{density}"

    def get_strength_type(value):
        val = str(value).lower()

        if "more than 14" in val:
            return "Algorithm_gt_14"
        elif "less than 14" in val:
            return "Algorithm_lt_14"
        elif val.strip():
            cleaned_val = (
                val.strip()
                .replace('/', '_')
                .replace(':', '')
                .replace('<', 'lt_')
                .replace('>', 'gt_')
                .replace('*', 'star')
                .replace('?', '')
            )
            return f"Algorithm_{cleaned_val}"
        else:
            return "Unknown_Algorithm"

    def get_cement_class(value):
        if not value or pd.isna(value):
            return "Unknown_Cement"
        val = str(value).strip().replace("/", "_").replace(':', '').replace('<', 'lt').replace('>', 'gt').replace('*',
                                                                                                                  'star').replace(
            '?', '')
        return f"Cement_{val}"

    def get_value(df, key_fragment):
        res = df[df["–ü–∞—Ä–∞–º–µ—Ç—Ä"].str.contains(key_fragment, case=False, na=False)]["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        return res.iloc[0] if not res.empty else None

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    try:
        files = [f for f in os.listdir(input_folder) if f.lower().endswith('.txt')]
        add_log_to_task(task_id, f"üìÑ –ù–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files)}", "info")

        for file_name in files:
            report_summary["Total Files Processed"] += 1
            input_path = os.path.join(input_folder, file_name)

            add_log_to_task(task_id, f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_name}", "info")

            try:
                with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
            except Exception as e:
                add_log_to_task(task_id, f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_name}: {e}", "error")
                report_summary["Errors (Read/Other)"] += 1
                continue

            # –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü –±–ª–æ–∫–æ–≤
            summary_start, data_start = None, None
            for i, line in enumerate(lines):
                if "--Summary--" in line or "--Test Summary--" in line:
                    summary_start = i
                elif "--Data--" in line:
                    data_start = i
                    break

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            is_uca_file = False
            summary_df = None

            if summary_start is not None and data_start is not None:
                summary_lines = lines[summary_start + 1:data_start]
                summary_data = []
                for line in summary_lines:
                    if not line.strip() or line.startswith("Full Path and File Name"):
                        continue
                    key, value = parse_summary_line(line)
                    if key:
                        summary_data.append((key, value))

                summary_df = pd.DataFrame(summary_data, columns=["–ü–∞—Ä–∞–º–µ—Ç—Ä", "–ó–Ω–∞—á–µ–Ω–∏–µ"])

                instrument_type = get_value(summary_df, "Instrument Type")

                if instrument_type and "uca" in str(instrument_type).lower():
                    is_uca_file = True
                    add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ Instrument Type)", "success")

            # 2. –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if not is_uca_file and "uca" in file_name.lower():
                is_uca_file = True
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê UCA ---
            if is_uca_file:
                report_summary["UCA Files"] += 1

                if summary_df is None:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫: UCA-—Ñ–∞–π–ª –±–µ–∑ –±–ª–æ–∫–æ–≤ Summary/Data", "warning")
                    report_summary["UCA - Incomplete/Error"] += 1
                    continue

                density_val = get_value(summary_df, "Density")
                strength_val = get_value(summary_df, "Compressive Strength")
                cement_val = get_value(summary_df, "CementClass")

                missing_params = []
                if not density_val:
                    missing_params.append("Density")
                if not strength_val:
                    missing_params.append("Compressive Strength")
                if not cement_val:
                    missing_params.append("CementClass")

                if not missing_params:
                    density_folder = get_density_range(density_val)
                    algorithm_folder = get_strength_type(strength_val)
                    cement_folder = get_cement_class(cement_val)
                    target_folder = os.path.join(output_folder, density_folder, algorithm_folder, cement_folder)
                    category_key = f"{density_folder}/{algorithm_folder}/{cement_folder}"
                    add_log_to_task(task_id,
                                    f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: Density={density_folder}, Strength={algorithm_folder}, Cement={cement_folder}",
                                    "success")
                else:
                    target_folder = os.path.join(output_folder, "Incomplete")
                    category_key = "Incomplete"
                    report_summary["UCA - Incomplete/Error"] += 1
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Incomplete: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç {', '.join(missing_params)}",
                                    "warning")

                if category_key not in report_summary["Distribution by UCA Category"]:
                    report_summary["Distribution by UCA Category"][category_key] = 0
                report_summary["Distribution by UCA Category"][category_key] += 1

                os.makedirs(target_folder, exist_ok=True)

                # Data —á–∞—Å—Ç—å
                data_lines = lines[data_start + 1:] if data_start else []
                data_str = "".join(data_lines).replace(",", ".")

                try:
                    data_df = pd.read_csv(StringIO(data_str), sep="\t")
                except Exception as e:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Data –≤ {file_name}: {e}", "error")
                    if category_key != 'Incomplete':
                        report_summary["UCA - Incomplete/Error"] += 1
                        if category_key in report_summary["Distribution by UCA Category"]:
                            report_summary["Distribution by UCA Category"][category_key] -= 1
                        report_summary["Distribution by UCA Category"]["Incomplete"] = report_summary[
                                                                                           "Distribution by UCA Category"].get(
                            "Incomplete", 0) + 1

                    target_folder = os.path.join(output_folder, "Incomplete")
                    os.makedirs(target_folder, exist_ok=True)
                    data_df = None
                    category_key = "Incomplete"

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                base_name = os.path.splitext(file_name)[0]
                summary_path = os.path.join(target_folder, f"{base_name}_summary.xlsx")
                summary_df.to_excel(summary_path, index=False)

                if data_df is not None:
                    data_path = os.path.join(target_folder, f"{base_name}_data.xlsx")
                    data_df.to_excel(data_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {target_folder}", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï-UCA (–£–ª—å—Ç—Ä–∞–ó–≤—É–∫) ---
            else:
                report_summary["Non-UCA Files (–£–ª—å—Ç—Ä–∞–ó–≤—É–∫)"] += 1
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: –£–ª—å—Ç—Ä–∞–ó–≤—É–∫", "info")

                rows = []
                for line in lines:
                    parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
                    if parts:
                        rows.append(parts)

                if not rows:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –§–∞–π–ª {file_name} –ø—É—Å—Ç", "warning")
                    report_summary["Errors (Read/Other)"] += 1
                    continue

                max_cols = max(len(r) for r in rows)
                col_names = [f"–ö–æ–ª–æ–Ω–∫–∞_{i + 1}" for i in range(max_cols)]
                df = pd.DataFrame([r + [''] * (max_cols - len(r)) for r in rows], columns=col_names)

                ultrasound_folder = os.path.join(output_folder, "–£–ª—å—Ç—Ä–∞–ó–≤—É–∫")
                os.makedirs(ultrasound_folder, exist_ok=True)

                base_name = os.path.splitext(file_name)[0]
                excel_path = os.path.join(ultrasound_folder, f"{base_name}.xlsx")
                df.to_excel(excel_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {ultrasound_folder}", "success")

        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, "üéâ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢", "success")
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üìÅ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {report_summary['Total Files Processed']}", "info")
        add_log_to_task(task_id, f"üîπ UCA-—Ñ–∞–π–ª—ã: {report_summary['UCA Files']}", "info")
        add_log_to_task(task_id, f"üîπ –£–ª—å—Ç—Ä–∞–ó–≤—É–∫: {report_summary['Non-UCA Files (–£–ª—å—Ç—Ä–∞–ó–≤—É–∫)']}", "info")
        add_log_to_task(task_id, f"üîπ Incomplete/Errors: {report_summary['UCA - Incomplete/Error']}", "info")
        add_log_to_task(task_id, f"üîπ –û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è: {report_summary['Errors (Read/Other)']}", "info")

        add_log_to_task(task_id, "\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï UCA-–§–ê–ô–õ–û–í:", "info")
        if report_summary["Distribution by UCA Category"]:
            for category, count in report_summary["Distribution by UCA Category"].items():
                add_log_to_task(task_id, f"  - {category}: {count} —à—Ç.", "info")
        else:
            add_log_to_task(task_id, "  (–ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö UCA-—Ñ–∞–π–ª–æ–≤)", "info")

        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")

        return {
            "processed": report_summary["Total Files Processed"],
            "output_folder": output_folder,
            "summary": report_summary
        }

    except Exception as e:
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}", "error")
        return {"error": str(e), "processed": 0}


# ========== API –≠–ù–î–ü–û–ò–ù–¢–´ ==========

@app.get("/")
async def root():
    return {
        "message": "File Processor API",
        "status": "running",
        "endpoints": [
            "/api/find-broken-files (POST) - –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤",
            "/api/parse-files (POST) - –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤",
            "/api/folders (GET) - —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –≤ data",
            "/api/task/{task_id}/logs (GET) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤",
            "/api/task/{task_id}/status (GET) - —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏",
            "/docs - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API"
        ]
    }


@app.get("/api/folders")
async def get_folders():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    data_dir = "/app/data"

    if not os.path.exists(data_dir):
        os.makedirs(data_dir, exist_ok=True)

    folders = []

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É data
    folders.append({
        "name": "data",
        "path": data_dir,
        "files_count": 0,
        "is_root": True
    })

    # –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫–∏ –≤ data
    try:
        for item in os.listdir(data_dir):
            item_path = os.path.join(data_dir, item)
            if os.path.isdir(item_path):
                # –°—á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
                files = []
                for root, dirs, filenames in os.walk(item_path):
                    for file in filenames:
                        if file.lower().endswith(('.tst', '.txt')):
                            files.append(os.path.join(root, file))

                folders.append({
                    "name": item,
                    "path": item_path,
                    "files_count": len(files),
                    "is_tests": item.lower() == "tests",
                    "has_tst_files": any(f.endswith('.tst') for f in os.listdir(item_path) if
                                         os.path.isfile(os.path.join(item_path, f))),
                    "has_txt_files": any(
                        f.endswith('.txt') for f in os.listdir(item_path) if os.path.isfile(os.path.join(item_path, f)))
                })
    except Exception as e:
        logger.error(f"Error scanning folders: {e}")

    return {
        "data_directory": data_dir,
        "folders": sorted(folders, key=lambda x: (not x.get('is_tests', False), x["name"]))
    }


@app.post("/api/find-broken-files", response_model=TaskResponse)
async def find_broken_files(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "find-broken",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat()
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_find_broken_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"Error in find-broken-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


@app.post("/api/parse-files", response_model=TaskResponse)
async def parse_files_endpoint(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "parse",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat()
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_parse_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"Error in parse-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


# ========== –§–û–ù–û–í–´–ï –ó–ê–î–ê–ß–ò ==========

async def process_find_broken_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–æ–∏—Å–∫–∞ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤...", "info")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            isolate_one_broken_tst,
            input_path,
            task_id
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        task_results[task_id] = result

        # –û—Ç–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result

        add_log_to_task(task_id, "‚úÖ –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")

    except Exception as e:
        logger.error(f"Error in process_find_broken_task: {e}")
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)


async def process_parse_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤...", "info")

        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            parse_files_task,
            input_path,
            task_id
        )

        task_results[task_id] = result
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result

        add_log_to_task(task_id, "‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!", "success")

    except Exception as e:
        logger.error(f"Error in process_parse_task: {e}")
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)


# ========== –≠–ù–î–ü–û–ò–ù–¢–´ –î–õ–Ø –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–Ø ==========

@app.get("/api/task/{task_id}/logs")
async def get_task_logs(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    task_info = current_tasks[task_id].copy()
    logs = task_info.get("logs", [])

    return {
        "task_id": task_id,
        "status": task_info.get("status", "unknown"),
        "type": task_info.get("type"),
        "folder_name": task_info.get("folder_name"),
        "started_at": task_info.get("started_at"),
        "completed_at": task_info.get("completed_at"),
        "logs": [log.dict() for log in logs]
    }


@app.get("/api/task/{task_id}/status")
async def get_task_status(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return {
        "task_id": task_id,
        "status": current_tasks[task_id].get("status", "unknown"),
        "type": current_tasks[task_id].get("type"),
        "started_at": current_tasks[task_id].get("started_at"),
        "completed_at": current_tasks[task_id].get("completed_at"),
        "has_result": task_id in task_results
    }


@app.get("/api/task/{task_id}/result")
async def get_task_result(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in task_results:
        raise HTTPException(status_code=404, detail="–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

    return {
        "task_id": task_id,
        "result": task_results[task_id],
        "retrieved_at": datetime.now().isoformat()
    }


@app.get("/api/tasks")
async def get_all_tasks():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    tasks = []
    for task_id, task_info in current_tasks.items():
        tasks.append({
            "id": task_id,
            "status": task_info.get("status", "unknown"),
            "type": task_info.get("type"),
            "folder_name": task_info.get("folder_name"),
            "started_at": task_info.get("started_at"),
            "logs_count": len(task_info.get("logs", []))
        })

    return {"tasks": tasks}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)