import asyncio
import os
import shutil
import re
import json
import pandas as pd
from io import StringIO
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List, Any
from contextlib import asynccontextmanager
import logging
import uuid
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á
current_tasks: Dict[str, Dict] = {}
task_results: Dict[str, Dict] = {}
HISTORY_FILE = "/app/data/processing_history.json"

# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
history_dir = os.path.dirname(HISTORY_FILE)
os.makedirs(history_dir, exist_ok=True)
if not os.path.exists(HISTORY_FILE):
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump([], f)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # Startup
    logger.info("–ó–∞–ø—É—Å–∫ File Processor API...")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    data_dir = "/app/data"
    tests_dir = os.path.join(data_dir, "Tests")
    results_dir = os.path.join(data_dir, "Results")

    os.makedirs(tests_dir, exist_ok=True)
    os.makedirs(results_dir, exist_ok=True)

    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö: {data_dir}")
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ç–µ—Å—Ç–æ–≤: {tests_dir}")
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {results_dir}")

    yield

    # Shutdown
    logger.info("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    save_history_to_file()


app = FastAPI(title="File Processor API", lifespan=lifespan)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class PathRequest(BaseModel):
    path: str


class TaskResponse(BaseModel):
    task_id: str
    message: str
    timestamp: str


class LogMessage(BaseModel):
    message: str
    type: str = "info"
    timestamp: str = None


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def save_history_to_file():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–∞–π–ª"""
    try:
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
        history_entries = []
        for task_id, task_info in current_tasks.items():
            if task_info.get("status") in ["completed", "failed"]:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏
                history_entry = {
                    "id": task_id,
                    "taskId": task_id,
                    "type": task_info.get("type"),
                    "status": task_info.get("status"),
                    "folderName": task_info.get("folder_name"),
                    "path": task_info.get("path"),
                    "startTime": task_info.get("started_at"),
                    "endTime": task_info.get("completed_at"),
                    "duration": None,
                    "error": task_info.get("error"),
                    "result": task_info.get("result"),
                    "logs": []
                }
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                if task_info.get("started_at") and task_info.get("completed_at"):
                    start = datetime.fromisoformat(task_info["started_at"])
                    end = datetime.fromisoformat(task_info["completed_at"])
                    duration_seconds = (end - start).seconds
                    if duration_seconds < 60:
                        history_entry["duration"] = f"{duration_seconds} —Å–µ–∫"
                    else:
                        history_entry["duration"] = f"{duration_seconds // 60} –º–∏–Ω {duration_seconds % 60} —Å–µ–∫"
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏
                logs = task_info.get("logs", [])
                if logs:
                    history_entry["logs"] = [
                        {
                            "message": log.message if hasattr(log, 'message') else str(log),
                            "type": log.type if hasattr(log, 'type') else "info",
                            "timestamp": log.timestamp if hasattr(log, 'timestamp') else task_info.get("started_at")
                        }
                        for log in logs
                    ]
                
                history_entries.append(history_entry)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        history_entries.sort(key=lambda x: x.get("startTime", ""), reverse=True)
        
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history_entries, f, ensure_ascii=False, indent=2)
        
        logger.info(f"–ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {HISTORY_FILE} ({len(history_entries)} –∑–∞–ø–∏—Å–µ–π)")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")


def load_history_from_file():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                history_data = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –∏–∑ —Ñ–∞–π–ª–∞: {len(history_data)} –∑–∞–ø–∏—Å–µ–π")
                return history_data
        else:
            logger.info("–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π")
            return []
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return []


def save_to_history(task_data: Dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –∏—Å—Ç–æ—Ä–∏—é
        history = load_history_from_file()
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏
        task_id = task_data.get("id") or task_data.get("task_id")
        history_entry = {
            "id": task_id or str(uuid.uuid4()),
            "taskId": task_id,
            "type": task_data.get("type"),
            "status": task_data.get("status"),
            "folderName": task_data.get("folder_name"),
            "path": task_data.get("path"),
            "startTime": task_data.get("started_at"),
            "endTime": task_data.get("completed_at"),
            "duration": None,
            "error": task_data.get("error"),
            "result": task_data.get("result"),
            "logs": []
        }
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if task_data.get("started_at") and task_data.get("completed_at"):
            start = datetime.fromisoformat(task_data["started_at"])
            end = datetime.fromisoformat(task_data["completed_at"])
            duration_seconds = (end - start).seconds
            if duration_seconds < 60:
                history_entry["duration"] = f"{duration_seconds} —Å–µ–∫"
            else:
                history_entry["duration"] = f"{duration_seconds // 60} –º–∏–Ω {duration_seconds % 60} —Å–µ–∫"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        logs = task_data.get("logs", [])
        if logs:
            history_entry["logs"] = [
                {
                    "message": log.message if hasattr(log, 'message') else log.get("message", str(log)),
                    "type": log.type if hasattr(log, 'type') else log.get("type", "info"),
                    "timestamp": log.timestamp if hasattr(log, 'timestamp') else log.get("timestamp", task_data.get("started_at"))
                }
                for log in logs
            ]
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å —Å —Ç–µ–º –∂–µ taskId –µ—Å–ª–∏ –µ—Å—Ç—å
        history = [h for h in history if h.get("taskId") != task_id]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        history.insert(0, history_entry)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        if len(history) > 100:
            history = history[:100]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏—é: {task_data.get('type')} - {task_data.get('folder_name')} ({len(logs)} –ª–æ–≥–æ–≤)")
        
        return history_entry
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é: {e}")
        return None


def add_log_to_task(task_id: str, message: str, type: str = "info"):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–æ–≥ –≤ –∑–∞–¥–∞—á—É"""
    if task_id not in current_tasks:
        current_tasks[task_id] = {"logs": [], "status": "running"}

    # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º timestamp –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    timestamp = datetime.now().isoformat()
    
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ message - —Å—Ç—Ä–æ–∫–∞
    if not isinstance(message, str):
        message = str(message)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    formatted_message = f"[{datetime.now().strftime('%H:%M:%S')}] {message}"
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ª–æ–≥–∞
    log_entry = LogMessage(
        message=formatted_message,
        type=type,
        timestamp=timestamp
    )
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –ø–∞–º—è—Ç—å)
    if "logs" not in current_tasks[task_id]:
        current_tasks[task_id]["logs"] = []
    
    current_tasks[task_id]["logs"].append(log_entry)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –ª–æ–≥–æ–≤
    if len(current_tasks[task_id]["logs"]) > 1000:
        current_tasks[task_id]["logs"] = current_tasks[task_id]["logs"][-1000:]
    
    print(f"üìù –î–æ–±–∞–≤–ª–µ–Ω –ª–æ–≥ –≤ –∑–∞–¥–∞—á—É {task_id}: {type} - {message[:50]}...")
    return log_entry


def find_all_broken_files(root_path: str, task_id: str):
    """–ù–∞—Ö–æ–¥–∏—Ç –í–°–ï –±–∏—Ç—ã–µ .tst —Ñ–∞–π–ª—ã –±–µ–∑ –ø–∞—Ä–Ω—ã—Ö .txt –≤–æ –í–°–ï–• –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–∞–ø–∫–∞—Ö"""
    add_log_to_task(task_id, "üîç –ù–ê–ß–ò–ù–ê–ï–ú –†–ï–ö–£–†–°–ò–í–ù–´–ô –ü–û–ò–°–ö –í–û –í–°–ï–• –ü–ê–ü–ö–ê–•...", "info")
    add_log_to_task(task_id, "=" * 50, "info")
    add_log_to_task(task_id, f"üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞: {os.path.basename(root_path)}", "info")
    add_log_to_task(task_id, f"üìÅ –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {root_path}", "info")
    
    total_found = 0
    total_processed = 0
    moved_files = []
    
    # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–ø–æ–∫
    folder_count = 0
    for root, dirs, files in os.walk(root_path):
        folder_count += 1
    
    add_log_to_task(task_id, f"üìä –í—Å–µ–≥–æ –ø–∞–ø–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {folder_count}", "info")
    
    current_folder = 0
    for folder, dirs, files in os.walk(root_path):
        current_folder += 1
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫—É "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ"
        if "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ" in folder:
            continue
            
        add_log_to_task(task_id, f"üìÇ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–∫–∏ [{current_folder}/{folder_count}]: {os.path.basename(folder)}", "info")
        add_log_to_task(task_id, f"   üìç –ü—É—Ç—å: {folder}", "info")

        # –ò—â–µ–º .tst —Ñ–∞–π–ª—ã
        tst_files = [f for f in files if f.lower().endswith(".tst")]
        
        if not tst_files:
            add_log_to_task(task_id, "   ‚úÖ .tst —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", "info")
            continue
            
        add_log_to_task(task_id, f"   üìÑ –ù–∞–π–¥–µ–Ω–æ .tst —Ñ–∞–π–ª–æ–≤: {len(tst_files)}", "info")
        
        folder_found = 0
        for tst in tst_files:
            total_processed += 1
            base = os.path.splitext(tst)[0]
            txt = base + ".txt"
            txt_path = os.path.join(folder, txt)

            if not os.path.exists(txt_path):
                # –ù–∞–π–¥–µ–Ω –±–∏—Ç—ã–π —Ñ–∞–π–ª!
                src = os.path.join(folder, tst)
                dest_dir = os.path.join(root_path, "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ")
                os.makedirs(dest_dir, exist_ok=True)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
                relative_path = os.path.relpath(folder, root_path)
                if relative_path != ".":
                    dest_dir = os.path.join(dest_dir, relative_path)
                    os.makedirs(dest_dir, exist_ok=True)
                
                dst = os.path.join(dest_dir, tst)

                try:
                    shutil.move(src, dst)
                    total_found += 1
                    folder_found += 1
                    moved_files.append({
                        "file": tst,
                        "from": folder,
                        "to": dest_dir,
                        "reason": f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {txt}"
                    })

                    add_log_to_task(task_id, "   ‚ö†Ô∏è –ë–ò–¢–´–ô –§–ê–ô–õ –ù–ê–ô–î–ï–ù ‚ö†Ô∏è", "warning")
                    add_log_to_task(task_id, f"      –§–∞–π–ª: {tst}", "info")
                    add_log_to_task(task_id, f"      –ü–∞–ø–∫–∞: {os.path.basename(folder)}", "info")
                    add_log_to_task(task_id, f"      –ü—Ä–∏—á–∏–Ω–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª {txt}", "info")
                    add_log_to_task(task_id, f"      –ü–µ—Ä–µ–º–µ—â–µ–Ω –≤: {dest_dir}", "success")

                except Exception as e:
                    add_log_to_task(task_id, f"      ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è: {e}", "error")
            else:
                # –§–∞–π–ª –Ω–µ –±–∏—Ç—ã–π
                add_log_to_task(task_id, f"   ‚úì {tst} - OK (–µ—Å—Ç—å {txt})", "info")
                    
        if folder_found > 0:
            add_log_to_task(task_id, f"   üìä –í –ø–∞–ø–∫–µ –Ω–∞–π–¥–µ–Ω–æ –±–∏—Ç—ã—Ö: {folder_found}", "success")
        else:
            add_log_to_task(task_id, f"   ‚úÖ –í –ø–∞–ø–∫–µ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç", "info")

    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    add_log_to_task(task_id, "=" * 50, "info")
    if total_found > 0:
        add_log_to_task(task_id, f"üéâ –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù! –ù–ê–ô–î–ï–ù–û: {total_found} –ë–ò–¢–´–• –§–ê–ô–õ–û–í", "success")
    else:
        add_log_to_task(task_id, "‚úÖ –ü–û–ò–°–ö –ó–ê–í–ï–†–®–ï–ù!", "success")
    
    add_log_to_task(task_id, f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_processed}", "info")
    add_log_to_task(task_id, f"üìä –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –ø–∞–ø–æ–∫: {current_folder}", "info")
    
    if total_found > 0:
        add_log_to_task(task_id, f"üìÅ –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ –≤: {os.path.join(root_path, '–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ')}", "info")
    else:
        add_log_to_task(task_id, "üì≠ –ë–ò–¢–´–• –§–ê–ô–õ–û–í –ù–ï –ù–ê–ô–î–ï–ù–û", "success")
    
    add_log_to_task(task_id, "=" * 50, "info")
    
    return {
        "found": total_found,
        "processed": total_processed,
        "folders_checked": current_folder,
        "moved_files": moved_files,
        "target_folder": os.path.join(root_path, "–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–ë–∏—Ç—ã–µ") if total_found > 0 else None,
        "message": f"–ù–∞–π–¥–µ–Ω–æ {total_found} –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤" if total_found > 0 else "–ë–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
    }


def parse_files_task(input_folder: str, task_id: str):
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"""
    add_log_to_task(task_id, f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤: {input_folder}", "info")

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É Results —Ä—è–¥–æ–º —Å Tests
    data_dir = "/app/data"
    relative_path = os.path.relpath(input_folder, data_dir)
    output_folder = os.path.join(data_dir, "Results", relative_path)
    os.makedirs(output_folder, exist_ok=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    report_summary = {
        "–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ": 0,
        "UCA —Ñ–∞–π–ª—ã": 0,
        "–î—Ä—É–≥–æ–µ —Ñ–∞–π–ª—ã": 0,
        "UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏": 0,
        "–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è": 0,
        "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA": {}
    }

    # –§—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
    def parse_summary_line(line):
        parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
        if not parts:
            return None, None
        if len(parts) == 3 and parts[0] in ("Information", "Calculated Curve"):
            return parts[1], parts[2]
        if len(parts) >= 2:
            return parts[0], " ".join(parts[1:])
        return parts[0], ""

    def get_density_range(density_value):
        try:
            density_str = re.findall(r"(\d+)", str(density_value))[0]
            density = int(density_str)
        except Exception:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è_–ø–ª–æ—Ç–Ω–æ—Å—Ç—å"

        if 1100 <= density <= 1499:
            return "1100-1499"
        elif 1500 <= density <= 1899:
            return "1500-1899"
        elif 1900 <= density <= 2500:
            return "1900-2500"
        else:
            return f"–î—Ä—É–≥–∞—è_{density}"

    def get_strength_type(value):
        val = str(value).lower()

        if "more than 14" in val:
            return "–ê–ª–≥–æ—Ä–∏—Ç–º_–±–æ–ª—å—à–µ_14"
        elif "less than 14" in val:
            return "–ê–ª–≥–æ—Ä–∏—Ç–º_–º–µ–Ω—å—à–µ_14"
        elif val.strip():
            cleaned_val = (
                val.strip()
                .replace('/', '_')
                .replace(':', '')
                .replace('<', '–º–µ–Ω—å—à–µ_')
                .replace('>', '–±–æ–ª—å—à–µ_')
                .replace('*', 'star')
                .replace('?', '')
            )
            return f"–ê–ª–≥–æ—Ä–∏—Ç–º_{cleaned_val}"
        else:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π_–∞–ª–≥–æ—Ä–∏—Ç–º"

    def get_cement_class(value):
        if not value or pd.isna(value):
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π_—Ü–µ–º–µ–Ω—Ç"
        val = str(value).strip().replace("/", "_").replace(':', '').replace('<', '–º–µ–Ω—å—à–µ').replace('>', '–±–æ–ª—å—à–µ').replace('*', 'star').replace('?', '')
        return f"–¶–µ–º–µ–Ω—Ç_{val}"

    def get_value(df, key_fragment):
        res = df[df["–ü–∞—Ä–∞–º–µ—Ç—Ä"].str.contains(key_fragment, case=False, na=False)]["–ó–Ω–∞—á–µ–Ω–∏–µ"]
        return res.iloc[0] if not res.empty else None

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        txt_files = []
        for root, dirs, files in os.walk(input_folder):
            for file in files:
                if file.lower().endswith('.txt'):
                    txt_files.append((root, file))
                    
        add_log_to_task(task_id, f"üìÑ –ù–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(txt_files)}", "info")

        for root, file_name in txt_files:
            report_summary["–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"] += 1
            input_path = os.path.join(root, file_name)
            relative_root = os.path.relpath(root, input_folder)

            add_log_to_task(task_id, f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_name}", "info")
            if relative_root != ".":
                add_log_to_task(task_id, f"   üìÅ –ü–∞–ø–∫–∞: {relative_root}", "info")

            try:
                with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
            except Exception as e:
                add_log_to_task(task_id, f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_name}: {e}", "error")
                report_summary["–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è"] += 1
                continue

            # –ü–æ–∏—Å–∫ –≥—Ä–∞–Ω–∏—Ü –±–ª–æ–∫–æ–≤
            summary_start, data_start = None, None
            for i, line in enumerate(lines):
                if "--Summary--" in line or "--Test Summary--" in line:
                    summary_start = i
                elif "--Data--" in line:
                    data_start = i
                    break

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            is_uca_file = False
            summary_df = None

            if summary_start is not None and data_start is not None:
                summary_lines = lines[summary_start + 1:data_start]
                summary_data = []
                for line in summary_lines:
                    if not line.strip() or line.startswith("Full Path and File Name"):
                        continue
                    key, value = parse_summary_line(line)
                    if key:
                        summary_data.append((key, value))

                summary_df = pd.DataFrame(summary_data, columns=["–ü–∞—Ä–∞–º–µ—Ç—Ä", "–ó–Ω–∞—á–µ–Ω–∏–µ"])

                instrument_type = get_value(summary_df, "Instrument Type")

                if instrument_type and "uca" in str(instrument_type).lower():
                    is_uca_file = True
                    add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ Instrument Type)", "success")

            # 2. –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if not is_uca_file and "uca" in file_name.lower():
                is_uca_file = True
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: UCA (–ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê UCA ---
            if is_uca_file:
                report_summary["UCA —Ñ–∞–π–ª—ã"] += 1

                if summary_df is None:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫: UCA-—Ñ–∞–π–ª –±–µ–∑ –±–ª–æ–∫–æ–≤ Summary/Data", "warning")
                    report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                    continue

                density_val = get_value(summary_df, "Density")
                strength_val = get_value(summary_df, "Compressive Strength")
                cement_val = get_value(summary_df, "CementClass")

                missing_params = []
                if not density_val:
                    missing_params.append("Density")
                if not strength_val:
                    missing_params.append("Compressive Strength")
                if not cement_val:
                    missing_params.append("CementClass")

                # –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞ UCA
                base_uca_folder = os.path.join(output_folder, "UCA")
                
                if not missing_params:
                    density_folder = get_density_range(density_val)
                    algorithm_folder = get_strength_type(strength_val)
                    cement_folder = get_cement_class(cement_val)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
                    if relative_root != ".":
                        target_folder = os.path.join(base_uca_folder, relative_root, density_folder, algorithm_folder, cement_folder)
                    else:
                        target_folder = os.path.join(base_uca_folder, density_folder, algorithm_folder, cement_folder)
                        
                    category_key = f"{density_folder}/{algorithm_folder}/{cement_folder}"
                    add_log_to_task(task_id,
                                    f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: –ü–ª–æ—Ç–Ω–æ—Å—Ç—å={density_folder}, –ü—Ä–æ—á–Ω–æ—Å—Ç—å={algorithm_folder}, –¶–µ–º–µ–Ω—Ç={cement_folder}",
                                    "success")
                else:
                    target_folder = os.path.join(base_uca_folder, relative_root, "–ù–µ–ø–æ–ª–Ω—ã–µ")
                    category_key = "–ù–µ–ø–æ–ª–Ω—ã–µ"
                    report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –ù–µ–ø–æ–ª–Ω—ã–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç {', '.join(missing_params)}",
                                    "warning")

                if category_key not in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
                    report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] = 0
                report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] += 1

                os.makedirs(target_folder, exist_ok=True)

                # Data —á–∞—Å—Ç—å
                data_lines = lines[data_start + 1:] if data_start else []
                data_str = "".join(data_lines).replace(",", ".")

                try:
                    data_df = pd.read_csv(StringIO(data_str), sep="\t")
                except Exception as e:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Data –≤ {file_name}: {e}", "error")
                    if category_key != '–ù–µ–ø–æ–ª–Ω—ã–µ':
                        report_summary["UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏"] += 1
                        if category_key in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
                            report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"][category_key] -= 1
                        report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]["–ù–µ–ø–æ–ª–Ω—ã–µ"] = report_summary[
                                                                                           "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"].get(
                            "–ù–µ–ø–æ–ª–Ω—ã–µ", 0) + 1

                    target_folder = os.path.join(base_uca_folder, relative_root, "–ù–µ–ø–æ–ª–Ω—ã–µ")
                    os.makedirs(target_folder, exist_ok=True)
                    data_df = None
                    category_key = "–ù–µ–ø–æ–ª–Ω—ã–µ"

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                base_name = os.path.splitext(file_name)[0]
                summary_path = os.path.join(target_folder, f"{base_name}_summary.xlsx")
                summary_df.to_excel(summary_path, index=False)

                if data_df is not None:
                    data_path = os.path.join(target_folder, f"{base_name}_data.xlsx")
                    data_df.to_excel(data_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {target_folder}", "success")

            # --- –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï-UCA (–î—Ä—É–≥–æ–µ) ---
            else:
                report_summary["–î—Ä—É–≥–æ–µ —Ñ–∞–π–ª—ã"] += 1
                add_log_to_task(task_id, "‚û°Ô∏è –¢–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: –î—Ä—É–≥–æ–µ", "info")

                rows = []
                for line in lines:
                    parts = [p.strip() for p in line.strip().split("\t") if p.strip()]
                    if parts:
                        rows.append(parts)

                if not rows:
                    add_log_to_task(task_id, f"‚ö†Ô∏è –§–∞–π–ª {file_name} –ø—É—Å—Ç", "warning")
                    report_summary["–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è"] += 1
                    continue

                max_cols = max(len(r) for r in rows)
                col_names = [f"–ö–æ–ª–æ–Ω–∫–∞_{i + 1}" for i in range(max_cols)]
                df = pd.DataFrame([r + [''] * (max_cols - len(r)) for r in rows], columns=col_names)

                # –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞ –î—Ä—É–≥–æ–µ
                base_other_folder = os.path.join(output_folder, "–î—Ä—É–≥–æ–µ")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
                if relative_root != ".":
                    other_folder = os.path.join(base_other_folder, relative_root)
                else:
                    other_folder = base_other_folder
                    
                os.makedirs(other_folder, exist_ok=True)

                base_name = os.path.splitext(file_name)[0]
                excel_path = os.path.join(other_folder, f"{base_name}.xlsx")
                df.to_excel(excel_path, index=False)

                add_log_to_task(task_id, f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {other_folder}", "success")

        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, "üéâ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢", "success")
        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üìÅ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {report_summary['–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ']}", "info")
        add_log_to_task(task_id, f"üîπ UCA-—Ñ–∞–π–ª—ã: {report_summary['UCA —Ñ–∞–π–ª—ã']}", "info")
        add_log_to_task(task_id, f"üîπ –î—Ä—É–≥–æ–µ: {report_summary['–î—Ä—É–≥–æ–µ —Ñ–∞–π–ª—ã']}", "info")
        add_log_to_task(task_id, f"üîπ –ù–µ–ø–æ–ª–Ω—ã–µ/–û—à–∏–±–∫–∏: {report_summary['UCA - –Ω–µ–ø–æ–ª–Ω—ã–µ/–æ—à–∏–±–∫–∏']}", "info")
        add_log_to_task(task_id, f"üîπ –û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è: {report_summary['–û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è']}", "info")

        add_log_to_task(task_id, "\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï UCA-–§–ê–ô–õ–û–í:", "info")
        if report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"]:
            for category, count in report_summary["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º UCA"].items():
                add_log_to_task(task_id, f"  - {category}: {count} —à—Ç.", "info")
        else:
            add_log_to_task(task_id, "  (–ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö UCA-—Ñ–∞–π–ª–æ–≤)", "info")

        add_log_to_task(task_id, "=" * 50, "info")
        add_log_to_task(task_id, f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_folder}", "success")
        add_log_to_task(task_id, "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")

        return {
            "processed": report_summary["–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"],
            "output_folder": output_folder,
            "structure": {
                "UCA": base_uca_folder if 'base_uca_folder' in locals() else os.path.join(output_folder, "UCA"),
                "–î—Ä—É–≥–æ–µ": base_other_folder if 'base_other_folder' in locals() else os.path.join(output_folder, "–î—Ä—É–≥–æ–µ")
            },
            "summary": report_summary
        }

    except Exception as e:
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}", "error")
        return {"error": str(e), "processed": 0}


# ========== API –≠–ù–î–ü–û–ò–ù–¢–´ ==========

@app.get("/")
async def root():
    return {
        "message": "File Processor API",
        "—Å—Ç–∞—Ç—É—Å": "—Ä–∞–±–æ—Ç–∞–µ—Ç",
        "—Ä—É—Å—Å–∫–∞—è_–≤–µ—Ä—Å–∏—è": "API –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤",
        "endpoints": [
            "/api/find-broken-files (POST) - –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤",
            "/api/parse-files (POST) - –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤",
            "/api/folders (GET) - —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –≤ data",
            "/api/task/{task_id}/logs (GET) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤",
            "/api/task/{task_id}/status (GET) - —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏",
            "/api/history (GET) - –∏—Å—Ç–æ—Ä–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            "/docs - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API"
        ]
    }


def get_folder_structure(base_path: str):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫"""
    structure = []
    
    try:
        for item in os.listdir(base_path):
            item_path = os.path.join(base_path, item)
            if os.path.isdir(item_path):
                # –°—á–∏—Ç–∞–µ–º .txt —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ –∏ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
                txt_count = 0
                for root, dirs, files in os.walk(item_path):
                    txt_count += len([f for f in files if f.lower().endswith('.txt')])
                
                folder_info = {
                    "name": item,
                    "path": item_path,
                    "files_count": txt_count,
                    "has_txt_files": txt_count > 0
                }
                
                # –ü–æ–ª—É—á–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
                subfolders = []
                try:
                    for sub_item in os.listdir(item_path):
                        sub_item_path = os.path.join(item_path, sub_item)
                        if os.path.isdir(sub_item_path):
                            sub_txt_count = 0
                            for root, dirs, files in os.walk(sub_item_path):
                                sub_txt_count += len([f for f in files if f.lower().endswith('.txt')])
                            
                            if sub_txt_count > 0:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏
                                subfolders.append({
                                    "name": sub_item,
                                    "path": sub_item_path,
                                    "files_count": sub_txt_count,
                                    "has_txt_files": sub_txt_count > 0
                                })
                except PermissionError:
                    pass
                
                if subfolders:
                    folder_info["subfolders"] = sorted(subfolders, key=lambda x: x["name"])
                
                structure.append(folder_info)
                
    except PermissionError as e:
        logger.error(f"Permission error accessing {base_path}: {e}")
    except Exception as e:
        logger.error(f"Error scanning {base_path}: {e}")
    
    return sorted(structure, key=lambda x: x["name"])


@app.get("/api/folders")
async def get_folders():
    """–ü–æ–ª—É—á–∞–µ—Ç –¥—Ä–µ–≤–æ–≤–∏–¥–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    data_dir = "/app/data"

    if not os.path.exists(data_dir):
        os.makedirs(data_dir, exist_ok=True)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    folders = get_folder_structure(data_dir)
    
    return {
        "data_directory": data_dir,
        "folders": folders
    }


@app.post("/api/find-broken-files", response_model=TaskResponse)
async def find_broken_files(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ - –î–õ–Ø –ì–õ–ê–í–ù–û–ô –°–¢–†–ê–ù–ò–¶–´"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "find-broken",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat(),
            "id": task_id
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤...", "info")

        # –°—Ä–∞–∑—É —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é (–Ω–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏)
        save_to_history(current_tasks[task_id])

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_find_broken_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–æ–∏—Å–∫ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ find-broken-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


@app.post("/api/parse-files", response_model=TaskResponse)
async def parse_files_endpoint(request: PathRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ - –î–õ–Ø –°–¢–†–ê–ù–ò–¶–´ –ü–ê–†–°–ï–†–ê"""
    try:
        task_id = str(uuid.uuid4())
        input_path = request.path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
        if not os.path.exists(input_path):
            raise HTTPException(status_code=400, detail=f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")

        if not os.path.isdir(input_path):
            raise HTTPException(status_code=400, detail=f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {input_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –≤ data –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_dir = "/app/data"
        if not input_path.startswith(data_dir):
            raise HTTPException(status_code=400, detail="–ú–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏ /app/data")

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        current_tasks[task_id] = {
            "logs": [],
            "status": "running",
            "type": "parse",
            "path": input_path,
            "folder_name": os.path.basename(input_path),
            "started_at": datetime.now().isoformat(),
            "id": task_id
        }

        add_log_to_task(task_id, f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É: {os.path.basename(input_path)}", "info")
        add_log_to_task(task_id, "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...", "info")

        # –°—Ä–∞–∑—É —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é (–Ω–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏)
        save_to_history(current_tasks[task_id])

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        background_tasks.add_task(
            process_parse_task,
            task_id,
            input_path
        )

        return TaskResponse(
            task_id=task_id,
            message=f"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ –≤ '{os.path.basename(input_path)}' –∑–∞–ø—É—â–µ–Ω",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ parse-files: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {str(e)}")


# ========== –§–û–ù–û–í–´–ï –ó–ê–î–ê–ß–ò ==========

async def process_find_broken_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–æ–∏—Å–∫–∞ –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –±–∏—Ç—ã—Ö .tst —Ñ–∞–π–ª–æ–≤...", "info")
        add_log_to_task(task_id, f"üìÅ –ü–∞–ø–∫–∞: {os.path.basename(input_path)}", "info")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            find_all_broken_files,
            input_path,
            task_id
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        task_results[task_id] = result
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result
        
        add_log_to_task(task_id, "‚úÖ –ó–∞–¥–∞—á–∞ –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", "success")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        save_to_history(current_tasks[task_id])
        
        print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏—é.")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ process_find_broken_task: {e}")
        add_log_to_task(task_id, f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        save_to_history(current_tasks[task_id])


async def process_parse_task(task_id: str, input_path: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –î–õ–Ø –°–¢–†–ê–ù–ò–¶–´ –ü–ê–†–°–ï–†–ê"""
    try:
        add_log_to_task(task_id, "üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤...", "info")

        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            parse_files_task,
            input_path,
            task_id
        )

        task_results[task_id] = result
        current_tasks[task_id]["status"] = "completed"
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        current_tasks[task_id]["result"] = result
        
        add_log_to_task(task_id, "‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!", "success")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        save_to_history(current_tasks[task_id])

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ process_parse_task: {e}")
        add_log_to_task(task_id, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", "error")
        current_tasks[task_id]["status"] = "failed"
        current_tasks[task_id]["error"] = str(e)
        current_tasks[task_id]["completed_at"] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        save_to_history(current_tasks[task_id])


# ========== –≠–ù–î–ü–û–ò–ù–¢–´ –î–õ–Ø –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–Ø ==========

@app.get("/api/task/{task_id}/logs")
async def get_task_logs(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history_data = load_history_from_file()
        history_task = next((h for h in history_data if h.get("taskId") == task_id), None)
        
        if history_task:
            return {
                "task_id": task_id,
                "status": history_task.get("status", "completed"),
                "type": history_task.get("type"),
                "folder_name": history_task.get("folderName"),
                "started_at": history_task.get("startTime"),
                "completed_at": history_task.get("endTime"),
                "logs": history_task.get("logs", [])
            }
        
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    task_info = current_tasks[task_id].copy()
    logs = task_info.get("logs", [])

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ª–æ–≥–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    formatted_logs = []
    for log in logs:
        if hasattr(log, 'dict'):
            formatted_logs.append(log.dict())
        elif isinstance(log, dict):
            formatted_logs.append(log)
        else:
            formatted_logs.append({
                "message": str(log),
                "type": "info",
                "timestamp": datetime.now().isoformat()
            })

    return {
        "task_id": task_id,
        "status": task_info.get("status", "unknown"),
        "type": task_info.get("type"),
        "folder_name": task_info.get("folder_name"),
        "started_at": task_info.get("started_at"),
        "completed_at": task_info.get("completed_at"),
        "logs": formatted_logs
    }


@app.get("/api/task/{task_id}/status")
async def get_task_status(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in current_tasks:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history_data = load_history_from_file()
        history_task = next((h for h in history_data if h.get("taskId") == task_id), None)
        
        if history_task:
            return {
                "task_id": task_id,
                "status": history_task.get("status", "completed"),
                "type": history_task.get("type"),
                "started_at": history_task.get("startTime"),
                "completed_at": history_task.get("endTime"),
                "has_result": True
            }
        
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return {
        "task_id": task_id,
        "status": current_tasks[task_id].get("status", "unknown"),
        "type": current_tasks[task_id].get("type"),
        "started_at": current_tasks[task_id].get("started_at"),
        "completed_at": current_tasks[task_id].get("completed_at"),
        "has_result": task_id in task_results
    }


@app.get("/api/task/{task_id}/result")
async def get_task_result(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏"""
    if task_id not in task_results:
        raise HTTPException(status_code=404, detail="–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

    return {
        "task_id": task_id,
        "result": task_results[task_id],
        "retrieved_at": datetime.now().isoformat()
    }


@app.get("/api/tasks")
async def get_all_tasks():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    tasks = []
    for task_id, task_info in current_tasks.items():
        tasks.append({
            "id": task_id,
            "status": task_info.get("status", "unknown"),
            "type": task_info.get("type"),
            "folder_name": task_info.get("folder_name"),
            "started_at": task_info.get("started_at"),
            "logs_count": len(task_info.get("logs", []))
        })

    return {"tasks": tasks}


@app.get("/api/history")
async def get_processing_history():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Ñ–∞–π–ª–∞
        history_data = load_history_from_file()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for task_id, task_info in current_tasks.items():
            if task_info.get("status") == "running":
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç—Ç–∞ –∑–∞–¥–∞—á–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏
                existing_index = next(
                    (i for i, h in enumerate(history_data) 
                     if h.get("taskId") == task_id), 
                    -1
                )
                
                if existing_index == -1:
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
                    history_entry = {
                        "id": task_id,
                        "taskId": task_id,
                        "type": task_info.get("type"),
                        "status": "running",
                        "folderName": task_info.get("folder_name"),
                        "path": task_info.get("path"),
                        "startTime": task_info.get("started_at"),
                        "endTime": None,
                        "duration": None,
                        "error": None,
                        "result": None,
                        "logs": [
                            {
                                "message": log.message if hasattr(log, 'message') else str(log),
                                "type": log.type if hasattr(log, 'type') else "info",
                                "timestamp": log.timestamp if hasattr(log, 'timestamp') else task_info.get("started_at")
                            }
                            for log in task_info.get("logs", [])
                        ]
                    }
                    history_data.insert(0, history_entry)
                else:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–≥–∏ —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
                    history_data[existing_index]["logs"] = [
                        {
                            "message": log.message if hasattr(log, 'message') else str(log),
                            "type": log.type if hasattr(log, 'type') else "info",
                            "timestamp": log.timestamp if hasattr(log, 'timestamp') else task_info.get("started_at")
                        }
                        for log in task_info.get("logs", [])
                    ]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        history_data.sort(key=lambda x: x.get("startTime") or "", reverse=True)
        
        logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {len(history_data)} –∑–∞–ø–∏—Å–µ–π")
        
        return {
            "history": history_data,
            "count": len(history_data),
            "retrieved_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)